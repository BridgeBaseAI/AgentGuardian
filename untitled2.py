
Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UcYH5rvp2VrVmcxHntw6Ut5Ysd9L0-xl
""

import os
import requests
import nest_asyncio
import uvicorn
import threading
from fastapi import FastAPI, HTTPException
from google import genai
from web3 import Web3

# 2. THE PATCH: This allows uvicorn to run inside the Colab loop
nest_asyncio.apply()

app = FastAPI()

# --- CONFIGURATION (Rotate your keys!) ---
ALCHEMY_URL = "https://base-mainnet.g.alchemy.com/v2/4bTDowwPPUbDttj0l3-w3"
GEMINI_KEY = "AIzaSyCRsaYdrIbtoI5ymNI0ujh-hI9LYrEJ6CM"
MY_WALLET = "0x3F491756716b5f4c4408bb0ba25aec92A5b2C51C"

client = genai.Client(api_key=GEMINI_KEY)
w3 = Web3(Web3.HTTPProvider(ALCHEMY_URL))

@app.get("/")
async def health_check():
    return {"status": "AgentGuardian is breathing", "network": "Base"}

@app.post("/audit")
async def run_audit(payment_tx: str, target_contract: str, calldata: str):
    # 1. FIND THE CORRECT MODEL NAME AUTOMATICALLY
    try:
        # We look for any model that supports 'generateContent'
        available_models = [m.name for m in client.models.list() if 'generateContent' in m.supported_generation_methods]
        # We prefer flash for speed, otherwise take the first one
        model_name = next((m for m in available_models if "flash" in m), available_models[0])
        print(f"Using model: {model_name}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Could not find a valid AI model: {str(e)}")

    # 2. PAYMENT CHECK (Same as before)
    if payment_tx != "TEST_MODE":
        try:
            tx = w3.eth.get_transaction_receipt(payment_tx)
            if not tx or tx.status != 1:
                raise HTTPException(status_code=402, detail="Payment failed.")
        except:
            raise HTTPException(status_code=400, detail="Invalid Transaction")

    # 3. SIMULATION (Same as before)
    sim_payload = {
        "id": 1, "jsonrpc": "2.0",
        "method": "alchemy_simulateAssetChanges",
        "params": [{"to": target_contract, "data": calldata}]
    }
    sim_response = requests.post(ALCHEMY_URL, json=sim_payload).json()

    # 4. AI ANALYSIS (Using the auto-detected model name)
    prompt = f"Audit this tx simulation. List 3 risks: {sim_response}"
    analysis = client.models.generate_content(model=model_name, contents=prompt)

    return {"status": "Success", "risk_report": analysis.text}

# 3. RUNNING THE SERVER
# We run this in a separate thread so your Colab cell doesn't get stuck.
def run_server():
    uvicorn.run(app, host="127.0.0.1", port=8000)

thread = threading.Thread(target=run_server)
thread.start()
print("üöÄ AgentGuardian is starting on http://127.0.0.1:8000")

import requests

# Test data
test_params = {
    "payment_tx": "TEST_MODE",
    "target_contract": "0x833589fCD6eDb6E08f4c7C32D4f71b54bdA02913", # USDC Address
    "calldata": "0x"
}

# This 'requests' call acts like a customer's browser
try:
    response = requests.post("http://127.0.0.1:8001/audit", params=test_params)
    if response.status_code == 200:
        print("‚úÖ SUCCESS!")
        print("AI Verdict:", response.json()['risk_report'])
    else:
        print(f"‚ùå FAILED with status {response.status_code}")
        print("Error details:", response.text)
except Exception as e:
    print(f"Could not connect to server: {e}")
